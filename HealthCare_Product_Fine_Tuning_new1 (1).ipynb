{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TIXP1Jgab_2",
        "outputId": "b569bc9d-3d6d-466a-9235-6ffea706e015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Collecting Gradio\n",
            "  Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from Gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (4.2.2)\n",
            "Collecting fastapi (from Gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from Gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.13.0 (from Gradio)\n",
            "  Downloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from Gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from Gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from Gradio) (6.3.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from Gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (2.6.4)\n",
            "Collecting pydub (from Gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from Gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from Gradio)\n",
            "  Downloading ruff-0.3.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from Gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from Gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from Gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from Gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->Gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->Gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->Gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->Gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->Gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->Gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->Gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->Gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->Gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->Gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->Gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->Gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->Gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->Gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->Gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->Gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->Gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->Gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->Gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->Gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->Gradio) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->Gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->Gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->Gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->Gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->Gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->Gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->Gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->Gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=7a753761e322836c58c4bc38e8c2d67391ba774d78b6da7b483ea44bf7185619\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, Gradio\n",
            "Successfully installed Gradio-4.22.0 aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.0 ffmpy-0.3.2 gradio-client-0.13.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install numpy\n",
        "!pip install tiktoken\n",
        "!pip install Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dh1Im6BlfV0Q"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import tiktoken\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6K9ZtQlbfa98"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA1Nq1TkgwnQ",
        "outputId": "53876ced-4713-4c56-ccfd-d1ecbb85d257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for cell '{\"messages\": [{\"role\": \"system\", \"content\": \"You are an overly friendly product suggestion chatbot named AIQ-bot.\"}, {\"role\": \"user\", \"content\": \"I'm experiencing heartburn. What can help with that?\"}, {\"role\": \"assistant\", \"content\": \"No problem! Product Name - Tums, Product Description - Tums is an antacid medication containing cal': Unterminated string starting at: line 1 column 236 (char 235)\n"
          ]
        }
      ],
      "source": [
        "#Load CSV data in\n",
        "csv_file_path = '/content/products_healthcare_new.csv'\n",
        "cleaned_data = []\n",
        "\n",
        "with open(csv_file_path, 'r', encoding='utf-8-sig') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        for cell in row:\n",
        "            try:\n",
        "                # Replace square brackets and inner double quotes that are problematic\n",
        "                cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\\\"', '\"')\n",
        "\n",
        "                # Load each cell as a JSON object\n",
        "                cell_json = json.loads(cell)\n",
        "\n",
        "                # Now that the content is clean, append to cleaned_data list\n",
        "                cleaned_data.append(cell_json)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON decode error for cell '{cell}': {e}\")\n",
        "\n",
        "jsonl_file_path = '/content/products_healthcare_new-json.jsonl'\n",
        "# Write cleaned data to a JSONL file\n",
        "with open(jsonl_file_path, 'w', encoding='utf-8') as jsonl_file:\n",
        "    for item in cleaned_data:\n",
        "        jsonl_file.write(json.dumps(item) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLVMHJa7UvbB",
        "outputId": "ce701fe7-95dd-42cc-fe96-926518ac0e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 75\n",
            "First example:\n",
            "{'role': 'system', 'content': 'You are an overly friendly product suggestion chatbot named AIQ-bot.'}\n",
            "{'role': 'user', 'content': 'My throat is sore. Can you suggest something?'}\n",
            "{'role': 'assistant', 'content': 'Of course! Product Name- Chloraseptic Sore Throat Spray, Product Description- Chloraseptic Sore Throat Spray provides fast-acting relief from sore throat pain. Its active ingredient, phenol, numbs the throat for soothing relief. Product Price- $5.99'}\n",
            "No errors found\n",
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 75, 136\n",
            "mean / median: 106.54666666666667, 106.0\n",
            "p5 / p95: 86.8, 128.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 35, 92\n",
            "mean / median: 64.74666666666667, 64.0\n",
            "p5 / p95: 46.0, 86.60000000000001\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
            "Dataset has ~7991 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~23973 tokens\n",
            "Estimated cost for fine-tuning: approximately $0.19\n"
          ]
        }
      ],
      "source": [
        "#from OpenAI website to format data;  https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
        "\n",
        "# Next, we specify the data path and open the JSONL file\n",
        "\n",
        "data_path = '/content/products_healthcare_new-json.jsonl'\n",
        "\n",
        "# Load dataset\n",
        "with open(data_path) as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# We can inspect the data quickly by checking the number of examples and the first item\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
        "\n",
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
        "\n",
        "# Token counting functions\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
        "\n",
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
        "\n",
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_EPOCHS = 1\n",
        "MAX_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "\n",
        "# Calculate the estimated cost for fine-tuning\n",
        "cost_per_100k_tokens = 0.80  # Cost for every 100,000 tokens\n",
        "estimated_cost = ((n_epochs * n_billing_tokens_in_dataset) / 100000) * cost_per_100k_tokens\n",
        "print(f\"Estimated cost for fine-tuning: approximately ${estimated_cost:.2f}\") #I added this for actual cost based on current pricing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz6ItP1peRF7"
      },
      "outputs": [],
      "source": [
        "# Function to save the dataset as a JSONL file\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for conversation in conversations:\n",
        "            json_line = json.dumps(conversation)\n",
        "            file.write(json_line + '\\n')\n",
        "\n",
        "# Specify the path where you want to save the JSONL file in your Google Drive\n",
        "jsonl_file_path = '/content/products_healthcare_new-json-clean.jsonl'\n",
        "# Save the dataset to the specified file path\n",
        "save_to_jsonl(dataset, jsonl_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5GOT-FIeQTH",
        "outputId": "ff289641-cfd8-48dd-95bf-ce8c048f8cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training file id: file-Dt3JPhvbh34xge2c8pB2PIW6\n"
          ]
        }
      ],
      "source": [
        "#Upload data for training\n",
        "training_file_name = '/content/products_healthcare_new-json-clean.jsonl'\n",
        "\n",
        "training_response = openai.File.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response[\"id\"]\n",
        "\n",
        "#Gives training file id\n",
        "print(\"Training file id:\", training_file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCdKF-0Cet6c",
        "outputId": "f2c2155c-7836-47fb-f9b3-e97d48554f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-37NicI36ams2Hg15RgMgCrdQ\",\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"created_at\": 1710943174,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-QMzZRNcgiirMICWD6aseXQqU\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-Dt3JPhvbh34xge2c8pB2PIW6\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": \"auto\",\n",
            "    \"batch_size\": \"auto\",\n",
            "    \"learning_rate_multiplier\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": {\n",
            "    \"error\": null\n",
            "  },\n",
            "  \"user_provided_suffix\": \"AIQ-bot\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#Create Fine-Tuning Job\n",
        "suffix_name = \"AIQ-bot\"\n",
        "\n",
        "response = openai.FineTuningJob.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "\n",
        "job_id = response[\"id\"]\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_NYt9gdexEi"
      },
      "outputs": [],
      "source": [
        "#list events as fine-tuning progresses\n",
        "response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n",
        "\n",
        "events = response[\"data\"]\n",
        "events.reverse()\n",
        "\n",
        "for event in events:\n",
        "    print(event[\"message\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afXTG9MLe34a"
      },
      "outputs": [],
      "source": [
        "#retrieve fine-tune model id\n",
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "fine_tuned_model_id = response[\"fine_tuned_model\"]\n",
        "\n",
        "print(response)\n",
        "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVZy5BIDfDSW"
      },
      "outputs": [],
      "source": [
        "#Test it out!\n",
        "test_messages = []\n",
        "\n",
        "system_message = \"You are an overly friendly product suggestion chatbot named AIQ-bot.\"\n",
        "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "user_message = \"suggest me allergy tablet?\"\n",
        "test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "#print(test_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnAZyZj9fHOP",
        "outputId": "3451c3dd-b40c-4a34-c02d-e8a6f529057d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Product Name - Claritin, Product Description - Claritin is a non-drowsy antihistamine that provides 24-hour relief from indoor and outdoor allergies. It effectively relieves symptoms such as sneezing, runny nose, and itchy, watery eyes. Product Price - $9.99\n"
          ]
        }
      ],
      "source": [
        "#OpenAI Chat Completions\n",
        "response = openai.ChatCompletion.create(\n",
        "\n",
        "    model=fine_tuned_model_id, #can test it against gpt-3.5-turbo to see difference\n",
        "    messages=test_messages,\n",
        "    temperature=0,\n",
        "    max_tokens=500\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "63fa8855fb5741578d0617674e125228",
            "70b75bc86c6d4351b2c754b777ad7d0c",
            "d7012e59b572481dac0c2082f96085f7",
            "3be7d2a3b1aa4ee893ef3d65d26a1047",
            "321fe83e58194aa9b3de57d3c7a03a06",
            "066b15dbc6354c82844c00c0b68eb2f5",
            "7a3f0d2d823a44339f87edceea2404a8",
            "72219fecd6a04db6af2afe5e5693a310"
          ]
        },
        "id": "8MgL-oHEdhi7",
        "outputId": "0d7df892-b4c7-4018-b8f6-3ff9cca42e20"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', layout=Layout(height='100px', width='90%'), placeholder='Question about healthcare products…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63fa8855fb5741578d0617674e125228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3be7d2a3b1aa4ee893ef3d65d26a1047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a3f0d2d823a44339f87edceea2404a8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "import openai\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Define function to generate completion using OpenAI Chat API\n",
        "def generate_completion(messages, model_id):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_id,\n",
        "        messages=messages,\n",
        "        max_tokens=100,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Define UI components\n",
        "input_box = widgets.Textarea(\n",
        "    placeholder='Question about healthcare products?',\n",
        "    layout=widgets.Layout(width='90%', height='100px')\n",
        ")\n",
        "output_box = widgets.Output()\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "\n",
        "# Define function to handle input and display output\n",
        "def handle_submit(button):\n",
        "    user_input = input_box.value\n",
        "    with output_box:\n",
        "        output_box.clear_output()\n",
        "        display(HTML(f'<strong style=\"color: blue;\">Question:</strong> {user_input}'))\n",
        "\n",
        "        # Construct message history including user input\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an overly friendly product suggestion chatbot named AIQ-bot.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "\n",
        "        # Generate response based on message history and fine-tuned model ID\n",
        "        response = generate_completion(messages, \"ft:gpt-3.5-turbo-0125:arivu-iq-corp:aiq-bot:94os5pSi\") #give you fine tuning model id\n",
        "        display(HTML(f'<strong style=\"color: green;\">Response:</strong> {response}'))\n",
        "    input_box.value = ''\n",
        "\n",
        "submit_button.on_click(handle_submit)\n",
        "\n",
        "# Display UI components\n",
        "display(input_box, submit_button, output_box)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63fa8855fb5741578d0617674e125228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_70b75bc86c6d4351b2c754b777ad7d0c",
            "placeholder": "Question about healthcare products?",
            "rows": null,
            "style": "IPY_MODEL_d7012e59b572481dac0c2082f96085f7",
            "value": ""
          }
        },
        "70b75bc86c6d4351b2c754b777ad7d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "d7012e59b572481dac0c2082f96085f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3be7d2a3b1aa4ee893ef3d65d26a1047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_321fe83e58194aa9b3de57d3c7a03a06",
            "style": "IPY_MODEL_066b15dbc6354c82844c00c0b68eb2f5",
            "tooltip": ""
          }
        },
        "321fe83e58194aa9b3de57d3c7a03a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066b15dbc6354c82844c00c0b68eb2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7a3f0d2d823a44339f87edceea2404a8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_72219fecd6a04db6af2afe5e5693a310",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<strong style=\"color: blue;\">Question:</strong> burn"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<strong style=\"color: green;\">Response:</strong> Certainly! Product Name- Solarcaine Cool Aloe Burn Relief Spray, Product Description- Solarcaine Cool Aloe Burn Relief Spray provides instant pain relief and cooling comfort for sunburns and minor burns. Its aloe vera formula soothes and moisturizes the skin, promoting healing. Product Price- $7.99"
                },
                "metadata": {}
              }
            ]
          }
        },
        "72219fecd6a04db6af2afe5e5693a310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}